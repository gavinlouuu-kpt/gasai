{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kedro.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext kedro.ipython\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/15/24 20:35:38] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">s3_conc_aligned_df</span> <span style=\"font-weight: bold\">(</span>ParquetDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>           <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#483\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">483</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/15/24 20:35:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208ms3_conc_aligned_df\u001b[0m \u001b[1m(\u001b[0mParquetDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m           \u001b]8;id=980812;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33590;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#483\u001b\\\u001b[2m483\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext kedro.ipython\n",
    "df = catalog.load(\"s3_conc_aligned_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp_no</th>\n",
       "      <th>timestamp_bin</th>\n",
       "      <th>A1_Resistance</th>\n",
       "      <th>A1_Resistance_diff</th>\n",
       "      <th>A1_Resistance_norm</th>\n",
       "      <th>A1_Sensor</th>\n",
       "      <th>A1_Sensor_diff</th>\n",
       "      <th>A1_Sensor_norm</th>\n",
       "      <th>SHT40_Humidity</th>\n",
       "      <th>SHT40_temp</th>\n",
       "      <th>index</th>\n",
       "      <th>resistance_ratio</th>\n",
       "      <th>ace_conc</th>\n",
       "      <th>expo_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>720650.750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4518.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.835</td>\n",
       "      <td>29.430</td>\n",
       "      <td>4481.5</td>\n",
       "      <td>1.768473</td>\n",
       "      <td>3.033000e-07</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>720361.875</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.999599</td>\n",
       "      <td>4519.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000332</td>\n",
       "      <td>42.840</td>\n",
       "      <td>29.435</td>\n",
       "      <td>4483.5</td>\n",
       "      <td>1.768473</td>\n",
       "      <td>3.033000e-07</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>719688.470</td>\n",
       "      <td>-673.405</td>\n",
       "      <td>0.998665</td>\n",
       "      <td>4523.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.001107</td>\n",
       "      <td>42.845</td>\n",
       "      <td>29.445</td>\n",
       "      <td>4485.5</td>\n",
       "      <td>1.768473</td>\n",
       "      <td>3.033000e-07</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>719015.940</td>\n",
       "      <td>-1634.810</td>\n",
       "      <td>0.997731</td>\n",
       "      <td>4526.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.001881</td>\n",
       "      <td>42.830</td>\n",
       "      <td>29.435</td>\n",
       "      <td>4487.5</td>\n",
       "      <td>1.768473</td>\n",
       "      <td>3.033000e-07</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>718727.905</td>\n",
       "      <td>-1345.095</td>\n",
       "      <td>0.997332</td>\n",
       "      <td>4528.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.002213</td>\n",
       "      <td>42.845</td>\n",
       "      <td>29.440</td>\n",
       "      <td>4489.5</td>\n",
       "      <td>1.768473</td>\n",
       "      <td>3.033000e-07</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\n",
       "   exp_no  timestamp_bin  A1_Resistance  A1_Resistance_diff  \\\n",
       "\u001b[1;36m0\u001b[0m       \u001b[1;36m0\u001b[0m            \u001b[1;36m0.0\u001b[0m     \u001b[1;36m720650.750\u001b[0m               \u001b[1;36m0.000\u001b[0m   \n",
       "\u001b[1;36m1\u001b[0m       \u001b[1;36m0\u001b[0m            \u001b[1;36m1.0\u001b[0m     \u001b[1;36m720361.875\u001b[0m               \u001b[1;36m0.000\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m       \u001b[1;36m0\u001b[0m            \u001b[1;36m2.0\u001b[0m     \u001b[1;36m719688.470\u001b[0m            \u001b[1;36m-673.405\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m       \u001b[1;36m0\u001b[0m            \u001b[1;36m3.0\u001b[0m     \u001b[1;36m719015.940\u001b[0m           \u001b[1;36m-1634.810\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m       \u001b[1;36m0\u001b[0m            \u001b[1;36m4.0\u001b[0m     \u001b[1;36m718727.905\u001b[0m           \u001b[1;36m-1345.095\u001b[0m   \n",
       "\n",
       "   A1_Resistance_norm  A1_Sensor  A1_Sensor_diff  A1_Sensor_norm  \\\n",
       "\u001b[1;36m0\u001b[0m            \u001b[1;36m1.000000\u001b[0m     \u001b[1;36m4518.0\u001b[0m             \u001b[1;36m0.0\u001b[0m        \u001b[1;36m1.000000\u001b[0m   \n",
       "\u001b[1;36m1\u001b[0m            \u001b[1;36m0.999599\u001b[0m     \u001b[1;36m4519.5\u001b[0m             \u001b[1;36m0.0\u001b[0m        \u001b[1;36m1.000332\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m            \u001b[1;36m0.998665\u001b[0m     \u001b[1;36m4523.0\u001b[0m             \u001b[1;36m3.5\u001b[0m        \u001b[1;36m1.001107\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m            \u001b[1;36m0.997731\u001b[0m     \u001b[1;36m4526.5\u001b[0m             \u001b[1;36m8.5\u001b[0m        \u001b[1;36m1.001881\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m            \u001b[1;36m0.997332\u001b[0m     \u001b[1;36m4528.0\u001b[0m             \u001b[1;36m7.0\u001b[0m        \u001b[1;36m1.002213\u001b[0m   \n",
       "\n",
       "   SHT40_Humidity  SHT40_temp   index  resistance_ratio      ace_conc  \\\n",
       "\u001b[1;36m0\u001b[0m          \u001b[1;36m42.835\u001b[0m      \u001b[1;36m29.430\u001b[0m  \u001b[1;36m4481.5\u001b[0m          \u001b[1;36m1.768473\u001b[0m  \u001b[1;36m3.033000e-07\u001b[0m   \n",
       "\u001b[1;36m1\u001b[0m          \u001b[1;36m42.840\u001b[0m      \u001b[1;36m29.435\u001b[0m  \u001b[1;36m4483.5\u001b[0m          \u001b[1;36m1.768473\u001b[0m  \u001b[1;36m3.033000e-07\u001b[0m   \n",
       "\u001b[1;36m2\u001b[0m          \u001b[1;36m42.845\u001b[0m      \u001b[1;36m29.445\u001b[0m  \u001b[1;36m4485.5\u001b[0m          \u001b[1;36m1.768473\u001b[0m  \u001b[1;36m3.033000e-07\u001b[0m   \n",
       "\u001b[1;36m3\u001b[0m          \u001b[1;36m42.830\u001b[0m      \u001b[1;36m29.435\u001b[0m  \u001b[1;36m4487.5\u001b[0m          \u001b[1;36m1.768473\u001b[0m  \u001b[1;36m3.033000e-07\u001b[0m   \n",
       "\u001b[1;36m4\u001b[0m          \u001b[1;36m42.845\u001b[0m      \u001b[1;36m29.440\u001b[0m  \u001b[1;36m4489.5\u001b[0m          \u001b[1;36m1.768473\u001b[0m  \u001b[1;36m3.033000e-07\u001b[0m   \n",
       "\n",
       "   expo_time  \n",
       "\u001b[1;36m0\u001b[0m        \u001b[1;36m3.0\u001b[0m  \n",
       "\u001b[1;36m1\u001b[0m        \u001b[1;36m3.0\u001b[0m  \n",
       "\u001b[1;36m2\u001b[0m        \u001b[1;36m3.0\u001b[0m  \n",
       "\u001b[1;36m3\u001b[0m        \u001b[1;36m3.0\u001b[0m  \n",
       "\u001b[1;36m4\u001b[0m        \u001b[1;36m3.0\u001b[0m  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "\n",
    "# Check for missing values and handle them if necessary\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Define the features and target\n",
    "features = ['timestamp_bin', 'A1_Resistance']\n",
    "target = 'resistance_ratio'\n",
    "\n",
    "# Extract the feature matrix and target vector\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "groups = df['exp_no']\n",
    "\n",
    "# Initialize the GroupShuffleSplit object for training/validation split\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split into training and temporary (validation + testing) sets\n",
    "train_idx, temp_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "# Create DataFrames for training and temporary sets\n",
    "train_df = df.iloc[train_idx]\n",
    "temp_df = df.iloc[temp_idx]\n",
    "\n",
    "# Split the temporary set into validation and testing sets\n",
    "gss_temp = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "val_idx, test_idx = next(gss_temp.split(temp_df[features], temp_df[target], groups=temp_df['exp_no']))\n",
    "\n",
    "# Create DataFrames for validation and testing sets\n",
    "val_df = temp_df.iloc[val_idx]\n",
    "test_df = temp_df.iloc[test_idx]\n",
    "\n",
    "# Extract features and targets for each set\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target]\n",
    "X_val = val_df[features]\n",
    "y_val = val_df[target]\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[target]\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/300], Train Loss: 1.9148, Validation Loss: 1.9173\n",
      "Epoch [20/300], Train Loss: 1.2878, Validation Loss: 1.2923\n",
      "Epoch [30/300], Train Loss: 0.8717, Validation Loss: 0.8776\n",
      "Epoch [40/300], Train Loss: 0.5955, Validation Loss: 0.6022\n",
      "Epoch [50/300], Train Loss: 0.4120, Validation Loss: 0.4192\n",
      "Epoch [60/300], Train Loss: 0.2901, Validation Loss: 0.2974\n",
      "Epoch [70/300], Train Loss: 0.2090, Validation Loss: 0.2164\n",
      "Epoch [80/300], Train Loss: 0.1551, Validation Loss: 0.1624\n",
      "Epoch [90/300], Train Loss: 0.1193, Validation Loss: 0.1264\n",
      "Epoch [100/300], Train Loss: 0.0954, Validation Loss: 0.1023\n",
      "Epoch [110/300], Train Loss: 0.0796, Validation Loss: 0.0862\n",
      "Epoch [120/300], Train Loss: 0.0690, Validation Loss: 0.0755\n",
      "Epoch [130/300], Train Loss: 0.0620, Validation Loss: 0.0682\n",
      "Epoch [140/300], Train Loss: 0.0573, Validation Loss: 0.0633\n",
      "Epoch [150/300], Train Loss: 0.0541, Validation Loss: 0.0601\n",
      "Epoch [160/300], Train Loss: 0.0521, Validation Loss: 0.0578\n",
      "Epoch [170/300], Train Loss: 0.0507, Validation Loss: 0.0563\n",
      "Epoch [180/300], Train Loss: 0.0498, Validation Loss: 0.0553\n",
      "Epoch [190/300], Train Loss: 0.0491, Validation Loss: 0.0546\n",
      "Epoch [200/300], Train Loss: 0.0487, Validation Loss: 0.0541\n",
      "Epoch [210/300], Train Loss: 0.0485, Validation Loss: 0.0538\n",
      "Epoch [220/300], Train Loss: 0.0483, Validation Loss: 0.0536\n",
      "Epoch [230/300], Train Loss: 0.0481, Validation Loss: 0.0534\n",
      "Epoch [240/300], Train Loss: 0.0481, Validation Loss: 0.0533\n",
      "Epoch [250/300], Train Loss: 0.0480, Validation Loss: 0.0532\n",
      "Epoch [260/300], Train Loss: 0.0480, Validation Loss: 0.0531\n",
      "Epoch [270/300], Train Loss: 0.0480, Validation Loss: 0.0531\n",
      "Epoch [280/300], Train Loss: 0.0479, Validation Loss: 0.0531\n",
      "Epoch [290/300], Train Loss: 0.0479, Validation Loss: 0.0530\n",
      "Epoch [300/300], Train Loss: 0.0479, Validation Loss: 0.0530\n",
      "Test Loss: 0.0466\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LinearNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearNN, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Define model, loss function, and optimizer\n",
    "input_dim = X_train.shape[1]\n",
    "model = LinearNN(input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass on training set\n",
    "    model.train()\n",
    "    train_outputs = model(X_train_tensor)\n",
    "    train_loss = criterion(train_outputs, y_train_tensor.view(-1, 1))\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_tensor)\n",
    "        val_loss = criterion(val_outputs, y_val_tensor.view(-1, 1))\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Validation Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# Testing the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_loss = criterion(test_outputs, y_test_tensor.view(-1, 1))\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
