{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kedro.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext kedro.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext kedro.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/16/24 21:18:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Registered line magic <span style=\"color: #008000; text-decoration-color: #008000\">'%reload_kedro'</span>                                   <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#51\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/16/24 21:18:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Registered line magic \u001b[32m'%reload_kedro'\u001b[0m                                   \u001b]8;id=111395;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=405708;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#51\u001b\\\u001b[2m51\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Registered line magic <span style=\"color: #008000; text-decoration-color: #008000\">'%load_node'</span>                                      <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#53\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Registered line magic \u001b[32m'%load_node'\u001b[0m                                      \u001b]8;id=251409;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=687515;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#53\u001b\\\u001b[2m53\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Resolved project path as: <span style=\"color: #800080; text-decoration-color: #800080\">/Users/gavinlou/Developer/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">gasai.</span>             <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#164\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         To set a different path, run <span style=\"color: #008000; text-decoration-color: #008000\">'%reload_kedro &lt;project_root&gt;'</span>            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Resolved project path as: \u001b[35m/Users/gavinlou/Developer/\u001b[0m\u001b[95mgasai.\u001b[0m             \u001b]8;id=138101;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=382456;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#164\u001b\\\u001b[2m164\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         To set a different path, run \u001b[32m'%reload_kedro \u001b[0m\u001b[32m<\u001b[0m\u001b[32mproject_root\u001b[0m\u001b[32m>\u001b[0m\u001b[32m'\u001b[0m            \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Kedro project gasAI                                                    <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#134\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">134</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Kedro project gasAI                                                    \u001b]8;id=854459;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=663751;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#134\u001b\\\u001b[2m134\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Defined global variable <span style=\"color: #008000; text-decoration-color: #008000\">'context'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'session'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'catalog'</span> and            <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#135\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'pipelines'</span>                                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Defined global variable \u001b[32m'context'\u001b[0m, \u001b[32m'session'\u001b[0m, \u001b[32m'catalog'\u001b[0m and            \u001b]8;id=796267;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=741560;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#135\u001b\\\u001b[2m135\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m'pipelines'\u001b[0m                                                            \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/16/24 21:18:28] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Registered line magic <span style=\"color: #008000; text-decoration-color: #008000\">'run_viz'</span>                                        <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">__init__.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#141\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/16/24 21:18:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Registered line magic \u001b[32m'run_viz'\u001b[0m                                        \u001b]8;id=272837;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py\u001b\\\u001b[2m__init__.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=768096;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/ipython/__init__.py#141\u001b\\\u001b[2m141\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext kedro.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #ff8700; text-decoration-color: #ff8700\">s3_conc_aligned_df</span> <span style=\"font-weight: bold\">(</span>ParquetDataset<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>           <a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#483\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">483</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[38;5;208ms3_conc_aligned_df\u001b[0m \u001b[1m(\u001b[0mParquetDataset\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m           \u001b]8;id=858400;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=90160;file:///Users/gavinlou/.pyenv/versions/3.10.13/envs/kedro/lib/python3.10/site-packages/kedro/io/data_catalog.py#483\u001b\\\u001b[2m483\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = catalog.load(\"s3_conc_aligned_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class GroupDataset(Dataset):\n",
    "    def __init__(self, X, y, groups):\n",
    "        self.X = X.unsqueeze(2)\n",
    "        self.y = y.unsqueeze(1)\n",
    "        self.groups = groups\n",
    "        self.group_to_indices = self._group_indices()\n",
    "\n",
    "    def _group_indices(self):\n",
    "        group_to_indices = {}\n",
    "        for idx, group in enumerate(self.groups):\n",
    "            if group not in group_to_indices:\n",
    "                group_to_indices[group] = []\n",
    "            group_to_indices[group].append(idx)\n",
    "        return group_to_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.groups[idx]\n",
    "\n",
    "class ExperimentSampler:\n",
    "    def __init__(self, group_to_indices, batch_size):\n",
    "        self.group_to_indices = group_to_indices\n",
    "        self.batch_size = batch_size\n",
    "        self.group_order = list(group_to_indices.keys())\n",
    "        np.random.shuffle(self.group_order)  # Shuffle the order of groups\n",
    "\n",
    "    def __iter__(self):\n",
    "        for group in self.group_order:\n",
    "            indices = self.group_to_indices[group]\n",
    "            for i in range(0, len(indices), self.batch_size):\n",
    "                yield indices[i:i + self.batch_size]\n",
    "\n",
    "    def __len__(self):\n",
    "        total_batches = 0\n",
    "        for indices in self.group_to_indices.values():\n",
    "            total_batches += (len(indices) + self.batch_size - 1) // self.batch_size\n",
    "        return total_batches\n",
    "\n",
    "# Define the features and target\n",
    "features = ['timestamp_bin', 'A1_Resistance']\n",
    "target = 'resistance_ratio'\n",
    "X_tensor = df[features]\n",
    "y_tensor = df[target]\n",
    "groups = df['exp_no']\n",
    "batch_size = 32\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_tensor.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_tensor.values, dtype=torch.float32)\n",
    "# Convert groups to NumPy array\n",
    "groups = np.array(groups)\n",
    "\n",
    "# Create dataset\n",
    "dataset = GroupDataset(X_tensor, y_tensor, groups)\n",
    "\n",
    "# 1. Split the data into training and testing sets using GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(test_size=0.2, n_splits=1, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X_tensor, y_tensor, groups=groups))\n",
    "\n",
    "# 2. Fit the scaler on the training data only\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_tensor[train_idx].numpy())  # Convert to NumPy if necessary and scale\n",
    "\n",
    "# 3. Transform the test data using the same scaler\n",
    "X_test_scaled = scaler.transform(X_tensor[test_idx].numpy())\n",
    "\n",
    "# Convert scaled data back to tensors\n",
    "X_train_scaled_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_test_scaled_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# 4. Create datasets\n",
    "train_dataset = GroupDataset(X_train_scaled_tensor, y_tensor[train_idx], groups[train_idx])\n",
    "test_dataset = GroupDataset(X_test_scaled_tensor, y_tensor[test_idx], groups[test_idx])\n",
    "\n",
    "# 5. Create experiment samplers\n",
    "train_sampler = ExperimentSampler(train_dataset.group_to_indices, batch_size)\n",
    "test_sampler = ExperimentSampler(test_dataset.group_to_indices, batch_size)\n",
    "\n",
    "# 6. Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_sampler=train_sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_sampler=test_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        out, _ = self.lstm(x, (h0,c0))  \n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train Loss: 0.0433 Val RMSE: 0.1540\n",
      "Epoch 2 Train Loss: 0.0111 Val RMSE: 0.1014\n",
      "Epoch 3 Train Loss: 0.0083 Val RMSE: 0.0933\n",
      "Epoch 4 Train Loss: 0.0077 Val RMSE: 0.0813\n",
      "Epoch 5 Train Loss: 0.0072 Val RMSE: 0.0723\n",
      "Epoch 6 Train Loss: 0.0067 Val RMSE: 0.0655\n",
      "Epoch 7 Train Loss: 0.0060 Val RMSE: 0.0587\n",
      "Epoch 8 Train Loss: 0.0052 Val RMSE: 0.0541\n",
      "Epoch 9 Train Loss: 0.0047 Val RMSE: 0.0546\n",
      "Epoch 10 Train Loss: 0.0045 Val RMSE: 0.0569\n",
      "Epoch 11 Train Loss: 0.0044 Val RMSE: 0.0583\n",
      "Epoch 12 Train Loss: 0.0043 Val RMSE: 0.0591\n",
      "Epoch 13 Train Loss: 0.0043 Val RMSE: 0.0594\n",
      "Epoch 14 Train Loss: 0.0042 Val RMSE: 0.0591\n",
      "Epoch 15 Train Loss: 0.0041 Val RMSE: 0.0587\n",
      "Epoch 16 Train Loss: 0.0040 Val RMSE: 0.0577\n",
      "Epoch 17 Train Loss: 0.0040 Val RMSE: 0.0566\n",
      "Epoch 18 Train Loss: 0.0039 Val RMSE: 0.0555\n",
      "Epoch 19 Train Loss: 0.0039 Val RMSE: 0.0545\n",
      "Epoch 20 Train Loss: 0.0038 Val RMSE: 0.0536\n",
      "Epoch 21 Train Loss: 0.0038 Val RMSE: 0.0529\n",
      "Epoch 22 Train Loss: 0.0037 Val RMSE: 0.0528\n",
      "Epoch 23 Train Loss: 0.0037 Val RMSE: 0.0529\n",
      "Epoch 24 Train Loss: 0.0036 Val RMSE: 0.0530\n",
      "Epoch 25 Train Loss: 0.0036 Val RMSE: 0.0532\n",
      "Epoch 26 Train Loss: 0.0036 Val RMSE: 0.0532\n",
      "Epoch 27 Train Loss: 0.0035 Val RMSE: 0.0532\n",
      "Epoch 28 Train Loss: 0.0035 Val RMSE: 0.0532\n",
      "Epoch 29 Train Loss: 0.0035 Val RMSE: 0.0535\n",
      "Epoch 30 Train Loss: 0.0034 Val RMSE: 0.0540\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from math import sqrt\n",
    "\n",
    "input_size = X_tensor.shape[1]\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "num_classes = 1\n",
    "\n",
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def calculate_rmse(outputs, labels):\n",
    "    mse = torch.mean((outputs - labels) ** 2)  # Calculate MSE as a tensor\n",
    "    return torch.sqrt(mse)  # Return RMSE as a tensor\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels, _ in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # print(inputs.shape)\n",
    "            inputs = inputs.transpose(1, 2)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "\n",
    "        # During validation\n",
    "        val_rmse = 0.0\n",
    "        total_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels, _ in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                inputs = inputs.transpose(1, 2)\n",
    "                outputs = model(inputs)\n",
    "                batch_rmse = calculate_rmse(outputs, labels) * inputs.size(0)\n",
    "                val_rmse += batch_rmse.item()  # Properly use .item() to convert tensor to float\n",
    "                total_samples += inputs.size(0)\n",
    "\n",
    "        val_rmse /= total_samples\n",
    "        print(f'Epoch {epoch+1} Train Loss: {epoch_loss:.4f} Val RMSE: {val_rmse:.4f}')\n",
    "\n",
    "# Training the model\n",
    "train_model(model, train_loader, test_loader, n_epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.7110],\n",
      "         [-0.7558]],\n",
      "\n",
      "        [[-1.7090],\n",
      "         [-0.7601]],\n",
      "\n",
      "        [[-1.7070],\n",
      "         [-0.7616]],\n",
      "\n",
      "        [[-1.7051],\n",
      "         [-0.7656]],\n",
      "\n",
      "        [[-1.7031],\n",
      "         [-0.7698]],\n",
      "\n",
      "        [[-1.7011],\n",
      "         [-0.7743]],\n",
      "\n",
      "        [[-1.6991],\n",
      "         [-0.7839]],\n",
      "\n",
      "        [[-1.6971],\n",
      "         [-0.7884]],\n",
      "\n",
      "        [[-1.6952],\n",
      "         [-0.8000]],\n",
      "\n",
      "        [[-1.6932],\n",
      "         [-0.8073]],\n",
      "\n",
      "        [[-1.6912],\n",
      "         [-0.8161]],\n",
      "\n",
      "        [[-1.6892],\n",
      "         [-0.8248]],\n",
      "\n",
      "        [[-1.6873],\n",
      "         [-0.8334]],\n",
      "\n",
      "        [[-1.6853],\n",
      "         [-0.8414]],\n",
      "\n",
      "        [[-1.6833],\n",
      "         [-0.8491]],\n",
      "\n",
      "        [[-1.6813],\n",
      "         [-0.8598]],\n",
      "\n",
      "        [[-1.6794],\n",
      "         [-0.8671]],\n",
      "\n",
      "        [[-1.6774],\n",
      "         [-0.8740]],\n",
      "\n",
      "        [[-1.6754],\n",
      "         [-0.8812]],\n",
      "\n",
      "        [[-1.6734],\n",
      "         [-0.8870]],\n",
      "\n",
      "        [[-1.6714],\n",
      "         [-0.8928]],\n",
      "\n",
      "        [[-1.6695],\n",
      "         [-0.9012]],\n",
      "\n",
      "        [[-1.6675],\n",
      "         [-0.9058]],\n",
      "\n",
      "        [[-1.6655],\n",
      "         [-0.9101]],\n",
      "\n",
      "        [[-1.6635],\n",
      "         [-0.9120]],\n",
      "\n",
      "        [[-1.6616],\n",
      "         [-0.9147]],\n",
      "\n",
      "        [[-1.6596],\n",
      "         [-0.9160]],\n",
      "\n",
      "        [[-1.6576],\n",
      "         [-0.9133]],\n",
      "\n",
      "        [[-1.6556],\n",
      "         [-0.9120]],\n",
      "\n",
      "        [[-1.6537],\n",
      "         [-0.9125]],\n",
      "\n",
      "        [[-1.6517],\n",
      "         [-0.9098]],\n",
      "\n",
      "        [[-1.6497],\n",
      "         [-0.9071]]])\n"
     ]
    }
   ],
   "source": [
    "# i want to examine the content of the loader to see if timestamps are being passed correctly\n",
    "\n",
    "for inputs, label, group in train_loader:\n",
    "    print(inputs)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([469995, 2])\n"
     ]
    }
   ],
   "source": [
    "print(X_tensor.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
